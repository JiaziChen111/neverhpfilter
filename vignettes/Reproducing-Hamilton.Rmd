---
title: "Reproducing Hamilton"
author: "Justin M Shea"
date: ' '
output:
  rmarkdown::html_document:
    toc: yes
vignette: >
  %\VignetteIndexEntry{Reproducing Hamilton}  
  %\VignetteEngine{knitr::rmarkdown}  
  %\VignetteEncoding{UTF-8}
---


\newpage

## Introduction

In the working paper titled "Why You Should Never Use the **H**odrick-**P**rescott Filter" <doi:10.3386/w23429>, James D. Hamilton proposes an approach to economic time series filtering which achieve goals the HP-Filter attempts, but does not produce. Part of the evolution in any field is making right that which has been wrong. In this vein, the `neverhpfilter` package implements Hamilton's contribution to Econometric time series filtering. 


The abstract from Hamilton(2017) offers an excellent introduction.


  >Here's why. 
  (1) The HP filter produces series with spurious dynamic relations that have no basis in the underlying data-generating process. 
  (2) Filtered values at the end of the sample are very different from those in the middle, and are also characterized by spurious dynamics.  
  (3) A statistical formalization of the problem typically produces values for the smoothing parameter vastly at odds with common practice, e.g., a value for $\lambda$ far below 1600 for quarterly data.  
  (4) Thereâ€™s a better alternative. A regression of the variable at date $t + h$ on the four most recent values as of date $t$ offers a robust approach to detrending that achieves all the objectives sought by users of the HP filter with none of its drawbacks.

## A Better Alternative

Fortunately, Hamilton doesn't just add to the list of critiques plaguing the Hodrick-Prescott filter, he offers a solution as well. For quarterly economic data, it can be described as an AR(4) process, additionally lagged by $h$ periods.

$$y_{t+h} = \beta_0 + \beta_1 y_t + \beta_2 y_{t-1} +\beta_3 y_{t-2} + \beta_4 y_{t-3} + v_{t+h}$$
$$\hat{v}_{t+h} = y_{t+h} + \hat{\beta}_0 + \hat{\beta}_1 y_t + \hat{\beta}_2 y_{t-1} + \hat{\beta}_3 y_{t-2} + \hat{\beta}_4 y_{t-3}$$

## Implementation in R

```{r, message = FALSE, warning = FALSE}
library(xts)
library(knitr)
library(neverHPfilter)
```

```{r eval=FALSE, include=FALSE}
# Real GDP
Real_Gross_Domestic_Product <- "https://fred.stlouisfed.org/data/GDPC1.txt"
GDPC1 <- as.xts(read.zoo(Real_Gross_Domestic_Product, skip = 16, index.column = 1,
                        header = TRUE, format = "%Y-%m-%d", FUN = as.yearqtr))

### Employment Rate ###
Total_nonfarm_Payrolls   <- "https://fred.stlouisfed.org/data/PAYEMS.txt"
PAYEMS <- as.xts(read.zoo(Total_nonfarm_Payrolls , sep = "", skip = 42, index.column = 1,
                                            header = TRUE, format = "%Y-%m-%d", FUN = as.yearmon))

# US Recessions
Recession_Indicators <- "https://fred.stlouisfed.org/data/USREC.txt"
USREC <- as.xts(read.zoo(Recession_Indicators , sep = "", skip = 69, index.column = 1,
                                   header = TRUE, format = "%Y-%m-%d", FUN = as.yearmon))
colnames(USREC) <- "USREC"
```

```{r, warning=FALSE, message=FALSE}
data(GDPC1)

log_RGDP <- 100*log(GDPC1)

gdp_filtered <- yth_filter(log_RGDP, h = 8, p = 4)

kable(tail(gdp_filtered))
```


```{r, warning = FALSE}
main <- "Log of Real GDP (GDPC1) and trend"
plot(gdp_filtered[,1:2], grid.col = "white", legend.loc = "topleft", main = main,  panels = 'lines(gdp_filtered[,3], type="h", on=NA)')
#abline(v = .index(qtr_recc2), type="h", lwd = 2, col = "lightgrey")
#plot(gdp_filtered[,1:2], grid.col = "white", legend.loc = "topleft", main = main)
#points(x=index(qtr_recc2), type="h", lwd = 2, on=1,col = "lightgrey")
#abline(v = .index(qtr_recc2), type="h", lwd = 2, col = "lightgrey")
```


```{r, warning = FALSE}
main <- "Log of Real GDP cycle and random walk"

plot(gdp_filtered[,3:4], grid.col = "white", legend.loc = "topright", main = main)
abline(h = 0, lty = 2, lwd = 2, col = "darkgreen")
#lines(panel.first = abline(v = .index(qtr_recc2), type="h", lwd = 2, col = "lightgrey"))
#addSeries(x = .index(qtr_recc2), type="h", lwd = 2, col = "lightgrey")

```


```{r, warning = FALSE}
# household
Employment_log <- 100*log(PAYEMS["1947/"])
employ_ar <- yth_glm(Employment_log, h = 24, p = 12)
employ_filtered <- yth_filter(Employment_log, h = 24, p = 12)

main <- "Log of Employment and trend"
plot(employ_filtered[,1:2], grid.col = "white", legend.loc = "topleft", main = main, panels = 'lines(employ_filtered[,3], type="h", on=NA)')
```


```{r, warning = FALSE}
main <- "Log of Employment cycle and random walk"
plot(employ_filtered[,3:4], grid.col = "white", legend.loc = "topright", main = main)
abline(h = 0, lty = 2, lwd = 2, col = "darkgreen")
```

# Comparing results to Hamilton's

Below is Table 2, found on pg. 40 of "Why You Should Never Use the Hodrick-Prescott Filter".

```{r}
data("Hamilton_table_2")

kable(Hamilton_table_2)
```



```{r, warning = FALSE}
GDP.St.Dev <- round(sd(gdp_filtered$GDPC1.cycle["/2016-1"], na.rm=TRUE), 2)
GDP.GDPCorr. <- cor(gdp_filtered$GDPC1.cycle["/2016-1"], gdp_filtered$GDPC1.cycle["/2016-1"], use = "complete.obs")

GDP.Random <- round(sd(coredata(gdp_filtered[,4]["/2016-1"]), na.rm=TRUE), 2)
GDP.RanCorr. <- cor(gdp_filtered[,4]["/2016-1"],gdp_filtered[,4]["/2016-1"], use = "complete.obs")

Sample <- gsub(" ","-",paste0(index(gdp_filtered[,1]),":",index(gdp_filtered["2016-1"])))
                 
GDP <- cbind(GDP.St.Dev, GDP.GDPCorr., GDP.Random, GDP.RanCorr., Sample)
colnames(GDP) <- names(Hamilton_table_2)
kable(GDP)

#round(sd(employ_filtered$PAYEMS.cycle["1947-1/2016-1"], na.rm=TRUE), 2)

```
